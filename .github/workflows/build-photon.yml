name: Photon - Import data and/or deploy

on:
  workflow_dispatch:
    inputs:
      build_import:
        description: 'Build import image?'
        required: true
        type: choice
        options:
          - 'no'
          - 'yes'
          - 'only-photon-data'
        default: 'no'
      deploy_env:
        description: 'Deploy Photon to (none = no deployment)'
        required: true
        type: choice
        options:
          - 'none'
          - 'dev'
          - 'staging'
          - 'both'
        default: 'none'
      photon_data_image_tag:
        description: 'Photon data image tag to use (default: latest, only used if not building import)'
        required: false
        default: 'latest'
        type: string
      photon_jar_url:
        description: 'Photon JAR URL'
        required: false
        type: string
        default: 'https://github.com/entur/photon/releases/download/linear-decay/photon-0.7.0.1.jar'

run-name: "Photon: ${{ inputs.build_import == 'yes' && 'all-data' || inputs.build_import == 'only-photon-data' && 'photon-data' || format('deploy:{0}', inputs.photon_data_image_tag) }} → ${{ inputs.deploy_env }}"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Run import and create artifacts
  nominatim-data:
    name: Nominatim Data
    if: inputs.build_import == 'yes'
    runs-on:
        group: grp-ubuntu-24.04-8core-x64
    permissions:
      contents: read
      id-token: write
    outputs:
      image_tag: ${{ steps.upload-nominatim-data.outputs.image_tag }}

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-java@v4
        with:
          distribution: 'liberica'
          java-version: '21'
          cache: gradle

      - name: Build converter JAR
        run: ./gradlew :converter:shadowJar

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get clean
          sudo apt-get purge -y needrestart
          sudo apt-get install -fy libarchive-tools

      - name: Run create-nominatim-data.sh
        run: ./create-nominatim-data.sh -z
        working-directory: converter

      - name: Generate stats summary
        working-directory: converter
        run: |
          echo "## Nominatim Data Generation Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f nominatim.ndjson.gz ] && [ -f nominatim.ndjson ]; then
            COMPRESSED_SIZE=$(du -h nominatim.ndjson.gz | cut -f1)
            UNCOMPRESSED_SIZE=$(du -h nominatim.ndjson | cut -f1)
            
            # Calculate compression ratio
            COMPRESSED_BYTES=$(stat -f%z nominatim.ndjson.gz 2>/dev/null || stat -c%s nominatim.ndjson.gz)
            UNCOMPRESSED_BYTES=$(stat -f%z nominatim.ndjson 2>/dev/null || stat -c%s nominatim.ndjson)
            RATIO=$(awk "BEGIN {printf \"%.1f\", $UNCOMPRESSED_BYTES / $COMPRESSED_BYTES}")
            
            # Count lines in uncompressed file
            LINE_COUNT=$(wc -l < nominatim.ndjson | tr -d ' ')
            
            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Compressed size | $COMPRESSED_SIZE |" >> $GITHUB_STEP_SUMMARY
            echo "| Uncompressed size | $UNCOMPRESSED_SIZE |" >> $GITHUB_STEP_SUMMARY
            echo "| Compression ratio | ${RATIO}x |" >> $GITHUB_STEP_SUMMARY
            echo "| Number of records | $LINE_COUNT |" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Required files not found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload nominatim data
        id: upload-nominatim-data
        uses: ./.github/actions/upload-docker-artifact
        with:
          image_name: geocoder-nominatim-data
          file_path: converter/nominatim.ndjson.gz
          workload_identity_provider: ${{ vars.CI_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ vars.CI_SERVICE_ACCOUNT }}

  photon-data:
    name: Photon Data
    if: |
      !cancelled() &&
      inputs.build_import != 'no' &&
      (inputs.build_import == 'only-photon-data' || needs.nominatim-data.result == 'success')
    needs: nominatim-data
    runs-on:
      group: grp-ubuntu-24.04-8core-x64
    permissions:
      contents: read
      id-token: write
    outputs:
      image_tag: ${{ steps.upload-photon-data.outputs.image_tag }}

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-java@v4
        with:
          distribution: 'liberica'
          java-version: '21'

      - name: Download nominatim data
        uses: ./.github/actions/download-docker-artifact
        with:
          image: geocoder-nominatim-data:${{ inputs.build_import == 'only-photon-data' && 'latest' || needs.nominatim-data.outputs.image_tag }}
          destination: converter
          workload_identity_provider: ${{ vars.CI_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ vars.CI_SERVICE_ACCOUNT }}

      - name: Run create-photon-data.sh
        working-directory: converter
        run: ./create-photon-data.sh -z "${{ inputs.photon_jar_url }}"

      - name: Generate stats summary
        working-directory: converter
        run: |
          echo "## Photon Data Generation Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f photon_data.tar.gz ]; then
            FILE_SIZE=$(du -h photon_data.tar.gz | cut -f1)
            UNCOMPRESSED_SIZE=$(gzip -l photon_data.tar.gz | tail -n 1 | awk '{print $5 $6}')
            COMPRESSION_RATIO=$(gzip -l photon_data.tar.gz | tail -n 1 | awk '{print $7}')
            
            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Archive size | $FILE_SIZE |" >> $GITHUB_STEP_SUMMARY
            echo "| Uncompressed size | $UNCOMPRESSED_SIZE |" >> $GITHUB_STEP_SUMMARY
            echo "| Compression ratio | $COMPRESSION_RATIO |" >> $GITHUB_STEP_SUMMARY
            
            # Show photon_data directory details if it exists
            if [ -d photon_data ]; then
              DIR_SIZE=$(du -sh photon_data | cut -f1)
              FILE_COUNT=$(find photon_data -type f | wc -l | tr -d ' ')
              echo "| Data directory size | $DIR_SIZE |" >> $GITHUB_STEP_SUMMARY
              echo "| Number of files | $FILE_COUNT |" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "❌ photon_data.tar.gz not found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload photon data
        id: upload-photon-data
        uses: ./.github/actions/upload-docker-artifact
        with:
          image_name: geocoder-photon-data
          file_path: converter/photon_data.tar.gz
          workload_identity_provider: ${{ vars.CI_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ vars.CI_SERVICE_ACCOUNT }}

  # Photon image jobs
  lint:
    name: Lint
    if: inputs.deploy_env != 'none'
    uses: entur/gha-docker/.github/workflows/lint.yml@v1
    with:
      dockerfile: photon/Dockerfile
      ignore: "DL3018,DL3059"

  build-push:
    name: Photon
    if: |
      !cancelled() &&
      inputs.deploy_env != 'none' &&
      (inputs.build_import == 'no' || needs.photon-data.result == 'success')
    needs: [lint, photon-data]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    outputs:
      image_tag: ${{ steps.build-push.outputs.image_tag }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Download photon data
        uses: ./.github/actions/download-docker-artifact
        with:
          image: geocoder-photon-data:${{ inputs.build_import != 'no' && needs.photon-data.outputs.image_tag || inputs.photon_data_image_tag }}
          destination: photon
          workload_identity_provider: ${{ vars.CI_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ vars.CI_SERVICE_ACCOUNT }}

      - name: Build and Push Photon image
        uses: ./.github/actions/docker-build-push
        with:
          image_name: geocoder-photon
          context: photon
          push: true
          build_args: PHOTON_JAR_URL=${{ inputs.photon_jar_url }}
          service_account: ${{ vars.CI_WORKLOAD_IDENTITY_PROVIDER }}
          workload_identity_provider: ${{ vars.CI_SERVICE_ACCOUNT }}

  scan:
    name: Scan
    if: |
      !cancelled() &&
      needs.build-push.result == 'success' &&
      inputs.deploy_env != 'none'
    needs: [build-push]
    uses: "./.github/workflows/_docker-scan.yml"
    with:
      image: "geocoder-photon:${{ needs.build-push.outputs.image_tag }}"

  # Deploy jobs
  dev-deploy:
    name: Dev
    if: |
      !cancelled() &&
      github.ref == 'refs/heads/main' &&
      needs.build-push.result == 'success' &&
      (inputs.deploy_env == 'dev' || inputs.deploy_env == 'both')
    needs: [build-push]
    uses: entur/gha-helm/.github/workflows/deploy.yml@v1
    with:
      environment: dev
      image: "geocoder-photon:${{ needs.build-push.outputs.image_tag }}"
      chart: helm/geocoder-photon
      namespace: geocoder
      release_name: geocoder-photon
    secrets: inherit

  acceptance-tests-dev:
    name: Dev Tests
    if: |
      !cancelled() &&
      needs.dev-deploy.result == 'success'
    needs: dev-deploy
    uses: "./.github/workflows/acceptance-tests.yml"
    with:
      environment: dev

  staging-deploy:
    name: Staging
    if: |
      !cancelled() &&
      github.ref == 'refs/heads/main' &&
      needs.build-push.result == 'success' &&
      (inputs.deploy_env == 'staging' || inputs.deploy_env == 'both')
    needs: [build-push]
    uses: entur/gha-helm/.github/workflows/deploy.yml@v1
    with:
      environment: tst
      image: "geocoder-photon:${{ needs.build-push.outputs.image_tag }}"
      chart: helm/geocoder-photon
      namespace: geocoder
      release_name: geocoder-photon
    secrets: inherit

  acceptance-tests-staging:
    name: Staging Tests
    if: |
      !cancelled() &&
      needs.staging-deploy.result == 'success'
    needs: staging-deploy
    uses: "./.github/workflows/acceptance-tests.yml"
    with:
      environment: staging
